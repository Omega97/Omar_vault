
# Semantic Statistics


Sometimes LLMs get stuck in a loop where they **repeat the same token** over and over again. 
$$\text{The slovenian word for a female teacher is "učitelj\_ica\_ica\_ica\_ica\_ica\_ica...}
$$
My goal si tu study why these models get stuck in these single-token loops. I've had an interesting idea about combining Statistical Mechanics (SM) with LLMs, in a framework that does not explicitly depend on a specific input, but rather uses a portion of the training dataset instead.

> We can take a layer of activations $q$ (a vector of length $N$) as a representative point for the system. The energy $H$ is the probability of outputting the **correct** token (as given by the dataset) minus the probability of outputting the **last** token of the input: 
$$
H(\mathbf{q}) = p_{\text{correct}}(\mathbf{q}) - p_{\text{last}}(\mathbf{q})
$$
> This energy is positive if the model is more likely to be correct than to repeat repeats the last token, zero if the model correctly repeats, and negative otherwise. If we run the model on the training data, when it wants to (incorrectly) repeat itself, it would get a negative spike in energy. With this setup we unlock a bridge between LLMs and SM. 

---

### Microcanonical Recipe

By following this recipe (standard in SM), we can evaluate the thermodynamical parameters for a model, independent of any specific input:

- Position  $\mathbf{q}$  (of fixed length $N$)
- **Hamiltonian**  $H(\mathbf{q})$
- **Phase-space volume**  $\Omega(E)=\int_{H(\mathbf{q})\le E} \, d^N q$
- **Entropy**  $S(E) = \ln \Omega(E)$
- **Temperature**  $T(E) = \left( \frac{\partial S}{\partial E} \right) ^{-1}$
- **Heat capacity**: $C(E) = \frac{\partial E}{\partial T}$
- **Free Energy** $F = E - T\,S$

These quantities are not dependent on an individual context. In principle, the set of inputs $\mathcal{D}=\{{x_1, ..., x_M}\}$ could be any subset of the input space, even the entire space itself. However, if we focus on when the model stutters, it's probably a good idea to restrain $\mathcal{D}$ to the training dataset (which, importantly, is not model-specific).

A position-energy pair can be easily generated by running the model through a given input. To evaluate $\Omega$, however, we need to approximate an integral over position space $\mathcal Q$. Entropy is just a function of the energy (**no input-dependence**!). Temperature is also easy to evaluate, as it is just a 1D partial derivative.

---

### Potential Goals

Current understanding attributes repetition to:

- **Low entropy decoding** (greedy/beam search)
- **Training data artifacts** (repetition in corpora)
- **Attention collapse** (degenerate attention patterns)
- **Diagnose models**: Compare $S(E)$ curves across architectures - do some have deeper “repetition wells”?
- **Regularization**: Add a term to training that penalizes low $H$ states (like an energy barrier).
-  **Sampling guidance**: During inference, reject steps that push $H$ below a threshold.
-  **Phase transition analogy**: Is there a critical “temperature” (diversity level) below which repetition becomes inevitable?

This framework could **unify these**: e.g., show that attention collapse causes a low-$H$ basin, which itself implies a high probability under microcanonical measure at negative energy.

---

### Notes
 
- Which inputs should we use? Random tokens, or the training set?
- In this framework we probably don't need the *momenta*.
- should the position be the input tokens or the activations?
- The temperature $T$ is not the commonly referred-to model temperature, which is not used on this case.
- What if the problem lies outside of the $\mathcal{Q}$ space?

---

### Addendum on Evaluating Omega


The central difficulty is evaluating the phase-space volume  
$$  
\Omega(E) = \int_{H(\mathbf q) \le E} d^N q  
$$ 
which is an extremely high-dimensional integral. Importantly, **the model does not explore the $\mathcal{Q}$ space uniformly**. Instead, activations concentrate on a highly structured, low-dimensional manifold induced by the data distribution and the network’s architecture.

If we naïvely estimate $\Omega(E)$ by counting how many sampled activations satisfy $H(\mathbf q)\le E$, we implicitly assume a uniform measure over $\mathcal Q$. This assumption is generally false and can lead to severe distortions. To correctly estimate $\Omega(E)$, we must therefore **estimate the local density of representative points**, rather than only using the raw frequency of observed states.


#### 1. Empirical Manifold Sampling

We begin by running a dataset $\mathcal D$ through the model and extracting activations at a fixed layer:  
$$
{\mathbf q_1, \mathbf q_2, \dots, \mathbf q_M}, \qquad \mathbf q_i \in \mathbb R^N.  
$$

Importantly, if we decide to use only a subset of the training dataset, the inputs should be chosen at random, to avoid high correlation between points. Each activation is mapped to an energy value via the Hamiltonian  
$$
H_i = H(\mathbf q_i) = p_{\text{correct}}(\mathbf{q_i}) - p_{\text{last}}(\mathbf{q_i})  
$$
that uses the probabilities of guessing the correct token and of guessing the last input token. This produces our empirical set of position-energy pairs.

#### 2. Estimating the Local Density on the Activation Manifold

To recover an estimate of the true phase-space volume, we introduce a **local density correction**. Let $\rho(\mathbf q)$ denote the local sampling density of activations around $\mathbf q$, estimated via any appropriate density-estimation algorithm of choice. 

#### 3. Density of States with Volume Weights

Finally, we can estimate $\Omega(E)$ for any energy, as:
$$
\Omega(E) = \sum_i{\frac{1(H(\mathbf{q}_i)<E)}{\rho(\mathbf{q}_i)}}
$$
We have calculated all the energies and densities once. We can now efficiently estimate this function on a 1D grid of points, and plug the result back into the *recipe* to recover the thermodynamic quantities of the model, like entropy and temperature.
