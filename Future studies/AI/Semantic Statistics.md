
# Semantic Statistics


Sometimes LLMs get stuck in a loop where they **repeat the same token** over and over again. $$
\text{The slovenian word for a female teacher is "učitelj\_ica\_ica\_ica\_ica\_ica\_ica...}
$$
My goal si tu study why these models get stuck in these single-token loops. I've had an interesting idea about combining Statistical Mechanics (SM) with LLMs, in a framework that does not explicitly depend on a specific input, but rather uses a portion of the training dataset instead.

> We can take a layer of activations $q$ (a vector of length $N$) as a representative point for the system. The energy $H$ is the probability of outputting the **correct** token (as given by the dataset) minus the probability of outputting the **last** token of the input: $$
H(\mathbf{q}) = p_{\text{correct}}(\mathbf{q}) - p_{\text{last}}(\mathbf{q})
$$
> This energy is positive if the model is more likely to be correct than to repeat repeats the last token, zero if the model correctly repeats, and negative otherwise. If we run the model on the training data, when it wants to (incorrectly) repeat itself, it would get a negative spike in energy. With this setup we unlock a bridge between LLMs and SM. 

---

### Microcanonical Recipe

By following this recipe (standard in SM), we can evaluate the thermodynamical parameters for a model, independent of any specific input:

- Position  $\mathbf{q}$  (of fixed length $N$)
- **Hamiltonian**  $H(\mathbf{q})$
- **Phase-space volume**  $\Omega(E)=\int_{H(\mathbf{q})\le E} \, d^N q$
- **Entropy**  $S(E) = \ln \Omega(E)$
- **Temperature**  $T(E) = \left( \frac{\partial S}{\partial E} \right) ^{-1}$

These quantities are context-independent. In principle the set of inputs $\mathcal{D}=\{{x_1, ..., x_M}\}$ could be any subset of the input space, even the entire space itself. However, if we focus on when the model stutters, it's probably a good idea to restrain $\mathcal{D}$ to the training dataset (which, importantly, is not model-specific).

A position-energy pair can be easily generated by running the model through a given input. To evaluate $\Omega$, however, we need to approximate an integral over position space $\mathcal Q$. Entropy is just a function of the energy (**no input-dependence**!). Temperature is also easy to evaluate, as it is just a 1D partial derivative.

---

### Potential Goals

Current understanding attributes repetition to:

- **Low entropy decoding** (greedy/beam search)
- **Training data artifacts** (repetition in corpora)
- **Attention collapse** (degenerate attention patterns)
- **Diagnose models**: Compare $S(E)$ curves across architectures - do some have deeper “repetition wells”?
2. **Regularization**: Add a term to training that penalizes low $H$ states (like an energy barrier).
3. **Sampling guidance**: During inference, reject steps that push $H$ below a threshold.
4. **Phase transition analogy**: Is there a critical “temperature” (diversity level) below which repetition becomes inevitable?

This framework could **unify these**: e.g., show that attention collapse causes a low-$H$ basin, which itself implies a high probability under microcanonical measure at negative energy.

---

### Notes
 
- Which inputs should we use? Random tokens, or the training set?
- In this framework we probably don't need the *momenta*.
- should the position be the input tokens or the activations?
- The temperature $T$ is not the commonly referred-to model temperature, which is not used on this case.

---


### Addendum on Evaluating Omega


The central difficulty in evaluating the phase-space volume  $$  
\Omega(E) = \int_{H(\mathbf q) \le E} d^N q  
$$ 
is that the activation space $\mathcal Q \subset \mathbb R^N$ is extremely high-dimensional and, more importantly, **the model never explores it uniformly**. Instead, activations concentrate on a highly structured, low-dimensional manifold induced by the data distribution and the network’s architecture.

If we naïvely estimate $\Omega(E)$ by counting how many sampled activations satisfy (H(\mathbf q)\le E), we implicitly assume a uniform measure over $\mathcal Q$. This assumption is generally false and can lead to severe distortions.

For example, if the true activation manifold were a 2D circle embedded in $\mathbb R^N$, but the sampling density were higher near the center, a simple histogram would vastly overestimate the volume of states near the origin—even though no such geometric volume exists there.

To correctly estimate $\Omega(E)$, we must therefore **factor out the local sampling density** and approximate the _intrinsic_ volume of the activation manifold rather than the raw frequency of observed states.


### 1. Empirical Manifold Sampling

As before, we begin by running a dataset $\mathcal D$ through the model and extracting activations at a fixed layer:  
$$
{\mathbf q_1, \mathbf q_2, \dots, \mathbf q_M}, \qquad \mathbf q_i \in \mathbb R^N.  
$$

Each activation is mapped to an energy value via the Hamiltonian  
$$
H_i = H(\mathbf q_i).  
$$

This produces an empirical ensemble of states, but this ensemble is distributed according to the **pushforward measure**  
$$
\mu (\mathbf q) = (f_\theta)_\# p_{\mathcal D}  
$$  
not the Lebesgue measure $d^N q$. Consequently, regions of high sampling density do not necessarily correspond to regions of large phase-space volume.


### 2. Estimating the Local Density on the Activation Manifold

To recover an estimate of the true phase-space volume, we introduce a **local density correction**.

Let $\rho(\mathbf q)$ denote the local sampling density of activations around $\mathbf q$, estimated for example via:

- $k$-nearest-neighbor density estimation,
    
- kernel density estimation (KDE),
    
- or local PCA–based volume elements.
    

Intuitively, (\rho(\mathbf q)) answers the question:

> _How many sampled states accumulate here because of the data distribution, rather than because this region has large intrinsic volume?_

Each sampled state is then assigned a **volume weight**  
$$
w(\mathbf q_i) \;\propto\; \frac{1}{\rho(\mathbf q_i)}.  
$$

This correction ensures that:

- densely sampled regions contribute _less_ volume per point,
    
- sparsely sampled regions contribute _more_ volume per point,
    
- and the resulting estimate approximates integration over the intrinsic manifold geometry rather than the empirical data frequency.

### 3. Density of States with Volume Weights

We now construct a **density of states** that accounts for the corrected measure. Instead of histogramming raw counts, we accumulate weighted contributions:  
$$
\rho(E) \;\approx\; \sum_{i=1}^{M} w(\mathbf q_i)\,\delta(E - H_i).  
$$

Operationally, this is implemented by binning energies and summing the corresponding weights within each bin.

This weighted density of states approximates the measure  
$$
\rho(E)\,dE \;\approx \; \int \delta(E - H(\mathbf q))\, d\Sigma(\mathbf q)
$$
where (d\Sigma) denotes the intrinsic volume element of the activation manifold.
