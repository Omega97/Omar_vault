
# Semantic Statistics


Sometimes LLMs get stuck in a loop where they **repeat the same token** over and over again. $$
\text{The slovenian word for a female teacher is "učitelj\_ica\_ica\_ica\_ica\_ica\_ica...}
$$
I've had an interesting idea about combining Statistical Mechanics (SM) with LLMs. My goal si tu study why these models get stuck in these single-token loops.

> We can take a layer of activations $q$ (a vector of length $N$) as a representative point for the system. The energy $H$ is the probability of outputting the **correct** token minus the probability of outputting the **last** token of the input: $$
H(\mathbf{q}) = p_{\text{correct}}(\mathbf{q}) - p_{\text{last}}(\mathbf{q})
$$
> This energy is positive if the model is more likely to be correct than to repeat repeats the last token, zero if the model correctly repeats, and negative otherwise. If we run the model on the training data, when it wants to (incorrectly) repeat itself, it would get a negative spike in energy. With this setup we unlock a bridge between LLMs and SM. 

---

### Microcanonical Recipe

By following this recipe (standard in SM), we can evaluate the thermodynamical parameters for a model, independent of any specific input:

- Position  $\mathbf{q}$  (of fixed length $N$)
- **Hamiltonian**  $H(\mathbf{q})$
- **Phase-space volume**  $\Omega(E)=\int_{H(\mathbf{q})\le E} \, d^N q$
- **Entropy**  $S(E) = \ln \Omega(E)$
- **Temperature**  $T(E) = \left( \frac{\partial S}{\partial E} \right) ^{-1}$

These quantities are context-independent. In principle the set of inputs $\mathcal{D}=\{{x_1, ..., x_M}\}$ could be any subset of the input space, even the entire space itself. However, if we focus on when the model stutters, it's probably a good idea to restrain $\mathcal{D}$ to the training dataset.

A position-energy pair can be easily generated by running the model through a given input. To evaluate $\Omega$, however, we need to approximate an integral over position space $\mathcal Q$. Entropy is just a function of the energy (**no input-dependence**!). Temperature is also easy to evaluate, as it is just a 1D partial derivative.

---

### Evaluating Omega

The difficult step is evaluating $\Omega$, an integral in hundreds of dimensions. Luckily, the integrand is binary (either 0 or 1, the value of $H$ is either lower or higher than the given energy $E$). Luckily, we don't have to re-compute it for various values of $E$, as all we need is (in principle) the distribution of values of $H$. The volume $\Omega$ is then just the cumulative function of this distribution.

The (approximate) evaluation process follows three core stages:

#### 1. Empirical Manifold Sampling

Since we cannot analytically integrate over the entire activation space, we approximate the measure of the space by sampling the model’s "natural" manifold. We pass a comprehensive dataset (the training set) through the model and record the internal activations at a chosen layer.

- **Observation Collection:** For a dataset of $M$ tokens, we extract a set of positions $\{\mathbf{q}_1, \mathbf{q}_2, \dots, \mathbf{q}_M\}$.
    
- **Energy Mapping:** Each position is mapped to a scalar energy value using the Hamiltonian $H(\mathbf{q}) = p_{\text{correct}} - p_{\text{last}}$. This results in an ensemble of $M$ energy observations.

#### 2. Density of States Estimation

The integral $\int_{H(\mathbf{q})\le E} \, d^N q$ is fundamentally a cumulative count of states. To solve it, we use *histogramming* to determine the **density of states**, $\rho(E)$, which describes how many activation states exist at any specific energy level.

#### 3. Cumulative Integration

Once we have $\rho(E)$, we compute $\Omega(E)$ by integrating the density of states from the lowest observed energy (in this case $E_{min}$ = -1) up to the threshold $E$:
$$
\Omega(E) = \int_{E_{min}}^{E} \rho(\epsilon) \, d\epsilon
$$

---

### Potential Goals

Current understanding attributes repetition to:

- **Low entropy decoding** (greedy/beam search)
- **Training data artifacts** (repetition in corpora)
- **Attention collapse** (degenerate attention patterns)
- **Diagnose models**: Compare $S(E)$ curves across architectures - do some have deeper “repetition wells”?
2. **Regularization**: Add a term to training that penalizes low $H$ states (like an energy barrier).
3. **Sampling guidance**: During inference, reject steps that push $H$ below a threshold.
4. **Phase transition analogy**: Is there a critical “temperature” (diversity level) below which repetition becomes inevitable?

This framework could **unify these**: e.g., show that attention collapse causes a low-$H$ basin, which itself implies a high probability under microcanonical measure at negative energy.

---

### Notes
 
- Which inputs should we use? Random tokens, or the training set?
- In this framework we probably don't need the *momenta*.
- should the position be the input tokens or the activations?
- The temperature $T$ is not the commonly referred-to model temperature, which is not used on this case.

