
Sometimes LLMs get stuck in a loop where they **repeat the same token** over and over again. $$
\text{The slovenian word for a female teacher is "učitelj\_ica\_ica\_ica\_ica\_ica\_ica...}
$$
I've had an interesting idea about combining Statistical Mechanics (SM) with LLMs. My goal si tu study why these models get stuck in these single-token loops.

> We can take a layer of activations $q$ (a vector of length $N$) as a representative point for the system. The energy $H$ is the probability of outputting the correct token minus the probability of outputting the last token of the input: $$
H(\mathbf{q}) = p_{\text{correct}}(\mathbf{q}) - p_{\text{last}}(\mathbf{q})
$$
> This energy is positive if the model is more likely to be correct than to repeat repeats the last token, zero if the model correctly repeats, and negative otherwise. If we run the model on the training data, when it wants to repeat itself, it would get a negative spike in energy. With this setup we unlock a bridge between LLMs and SM. 

---

### Microcanonical Recipe

By following this recipe (standard in SM), we can evaluate the thermodynamical parameters for a model, independent of any specific input:

- Position  $\mathbf{q}$  (of fixed length $N$)
- **Hamiltonian**  $H(\mathbf{q})$
- **Phase-space volume**  $\Omega(E)=\int_{H(\mathbf{q})\le E} \, d^N q$
- **Entropy**  $S(E) = \ln \Omega(E)$
- **Temperature**  $T(E) = \left( \frac{\partial S}{\partial E} \right) ^{-1}$

These quantities are context-independent. In principle the set of inputs $\mathcal{D}=\{{x_1, ..., x_M}\}$ could be any subset of the input space, even the entire space itself. However, if we focus on when the model stutters, it's probably a good idea to restrain $\mathcal{D}$ to the training dataset.

A position-energy pair can be easily generated by running the model through a given input. To evaluate $\Omega$, however, we need to approximate an integral over position space $\mathcal Q$. Entropy is just a function of the energy (**no input-dependence**!). Temperature is also easy to evaluate, as it is just a 1D partial derivative.

---

### Potential Goals

Current understanding attributes repetition to:

- **Low entropy decoding** (greedy/beam search)
- **Training data artifacts** (repetition in corpora)
- **Attention collapse** (degenerate attention patterns)
- **Diagnose models**: Compare $S(E)$ curves across architectures - do some have deeper “repetition wells”?
2. **Regularization**: Add a term to training that penalizes low $H$ states (like an energy barrier).
3. **Sampling guidance**: During inference, reject steps that push $H$ below a threshold.
4. **Phase transition analogy**: Is there a critical “temperature” (diversity level) below which repetition becomes inevitable?

This framework could **unify these**: e.g., show that attention collapse causes a low-$H$ basin, which itself implies a high probability under microcanonical measure at negative energy.

---

### Notes
 
- Which inputs should we use? Random tokens, or the training set?
- In this framework we probably don't need the *momenta*.
- should the position be the input tokens or the activations?
- The temperature $T$ is not the commonly referred-to model temperature, which is not used on this case.

